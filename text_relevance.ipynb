{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import re\n",
    "from multiprocessing import Pool, Lock, Value\n",
    "from time import sleep\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv('queries.numerate.txt', sep='\t', header=None)\n",
    "urls = pd.read_csv('urls.numerate.txt', sep='\t', header=None)\n",
    "urls.index = urls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170711/doc.4873.dat',\n",
       " '20170711/doc.4874.dat',\n",
       " '20170711/doc.4875.dat',\n",
       " '20170711/doc.4876.dat',\n",
       " '20170711/doc.4877.dat']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docnames = []\n",
    "\n",
    "listdir = os.listdir('content/content/')\n",
    "\n",
    "for d in listdir:\n",
    "    listdocs = os.listdir('content/content/' + d)\n",
    "    listdocs.sort()\n",
    "    docnames += list(map(lambda x: d + '/' + x, listdocs))\n",
    "docnames[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2words(docname):\n",
    "    with open('content/content/' + docname, errors='ignore') as read_file:\n",
    "        lines = list(read_file)\n",
    "    url = lines[0].strip()\n",
    "    html = \"\".join(lines[1:])\n",
    "    soup = BeautifulSoup(html)\n",
    "    doc_id = urls.at[url, 0]\n",
    "    if soup.text:\n",
    "        text = re.sub(r'[^A-Za-zА-Яа-я0-9]+', ' ', soup.text)\n",
    "    else:\n",
    "        text = \"\"\n",
    "    if soup.title:\n",
    "        if soup.title.text:\n",
    "            title = re.sub(r'[^A-Za-zА-Яа-я0-9]+', ' ', soup.title.text)\n",
    "        else:\n",
    "            title = \"\"\n",
    "    else:\n",
    "        title = \"\"\n",
    "\n",
    "    return (title + text, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38110 objects are processed..."
     ]
    }
   ],
   "source": [
    "mutex = Lock()\n",
    "n_processed = Value('i', 0)\n",
    "\n",
    "def func_wrapper(docname):\n",
    "    res = doc2words(docname) \n",
    "    with mutex:\n",
    "        # в этом блоке можно безопасно менять общие объекты для процессов\n",
    "        global n_processed\n",
    "        n_processed.value += 1\n",
    "        if n_processed.value % 10 == 0:\n",
    "            print(f\"\\r{n_processed.value} objects are processed...\", end='', flush=True)\n",
    "    return res\n",
    "\n",
    "with Pool(processes=10) as pool:\n",
    "    docs = pool.map(func_wrapper, docnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21640</th>\n",
       "      <td>1</td>\n",
       "      <td>Хорватия Хорватия EVA RU Вход Европа Черногори...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21950</th>\n",
       "      <td>2</td>\n",
       "      <td>Три недели в Европе Начало Три недели в Европе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21172</th>\n",
       "      <td>3</td>\n",
       "      <td>Как правильно сделать визу в Польшу шенген Q A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>4</td>\n",
       "      <td>Новости Новости О нас Отрасли Страны Новости О...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20285</th>\n",
       "      <td>5</td>\n",
       "      <td>Аллергия на Магические Грибы fb2 КулЛиб Классн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "21640   1  Хорватия Хорватия EVA RU Вход Европа Черногори...\n",
       "21950   2  Три недели в Европе Начало Три недели в Европе...\n",
       "21172   3  Как правильно сделать визу в Польшу шенген Q A...\n",
       "20002   4  Новости Новости О нас Отрасли Страны Новости О...\n",
       "20285   5  Аллергия на Магические Грибы fb2 КулЛиб Классн..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_text = list(map(lambda x: x[0], docs))\n",
    "docs_id = list(map(lambda x: x[1], docs))\n",
    "\n",
    "doc_df = pd.DataFrame({'id': docs_id, 'text': docs_text})\n",
    "doc_df = doc_df.sort_values(by=['id'])\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df.to_csv(\"text_relevance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = pd.read_csv(\"text_relevance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anse/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words |= set(stopwords.words('russian'))\n",
    "with open('stop_words.txt', \"r\") as rf:\n",
    "    lines = [line.strip() for line in rf]\n",
    "stop_words |= set(lines)\n",
    "stop_words |= set(['.', '...', '-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38114 entries, 0 to 38113\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  38114 non-null  int64 \n",
      " 1   id          38114 non-null  int64 \n",
      " 2   text        38114 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 893.4+ KB\n"
     ]
    }
   ],
   "source": [
    "doc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df.index = doc_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21640</td>\n",
       "      <td>1</td>\n",
       "      <td>Хорватия Хорватия EVA RU Вход Европа Черногори...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21950</td>\n",
       "      <td>2</td>\n",
       "      <td>Три недели в Европе Начало Три недели в Европе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21172</td>\n",
       "      <td>3</td>\n",
       "      <td>Как правильно сделать визу в Польшу шенген Q A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20002</td>\n",
       "      <td>4</td>\n",
       "      <td>Новости Новости О нас Отрасли Страны Новости О...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20285</td>\n",
       "      <td>5</td>\n",
       "      <td>Аллергия на Магические Грибы fb2 КулЛиб Классн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  id                                               text\n",
       "id                                                                   \n",
       "1        21640   1  Хорватия Хорватия EVA RU Вход Европа Черногори...\n",
       "2        21950   2  Три недели в Европе Начало Три недели в Европе...\n",
       "3        21172   3  Как правильно сделать визу в Польшу шенген Q A...\n",
       "4        20002   4  Новости Новости О нас Отрасли Страны Новости О...\n",
       "5        20285   5  Аллергия на Магические Грибы fb2 КулЛиб Классн..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{term1: [[doc_id1, term_freq1], [doc_id2, term_freq2], ...], term2: ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "# for id, doc in tqdm(doc_df.iterrows(), total=38114, position=0):\n",
    "def create_index(doc_row):\n",
    "    id, doc = doc_row\n",
    "    loc_index = {}\n",
    "    terms = doc['text'].split()\n",
    "    terms = [t.lower() for t in terms]\n",
    "    terms = [t for t in terms if not t in stop_words]\n",
    "    terms = [stemmer.stem(term) for term in terms]\n",
    "    for term in terms:\n",
    "        if term in loc_index.keys():\n",
    "            doc_id, num = loc_index[term][-1]\n",
    "            if doc_id == id:\n",
    "                loc_index[term][-1][1] += 1\n",
    "            else:\n",
    "                loc_index[term].append([id, 1])\n",
    "        else:\n",
    "            loc_index[term] = [[id, 1]]\n",
    "            \n",
    "    # computing tf\n",
    "    for term in terms:\n",
    "        loc_index[term][-1][1] /= len(terms)\n",
    "    return loc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8110 objects are processed..."
     ]
    }
   ],
   "source": [
    "mutex = Lock()\n",
    "n_processed = Value('i', 0)\n",
    "\n",
    "def func_wrapper(doc_row):\n",
    "    res = create_index(doc_row) \n",
    "    with mutex:\n",
    "        # в этом блоке можно безопасно менять общие объекты для процессов\n",
    "        global n_processed\n",
    "        n_processed.value += 1\n",
    "        if n_processed.value % 10 == 0:\n",
    "            print(f\"\\r{n_processed.value} objects are processed...\", end='', flush=True)\n",
    "    return res\n",
    "\n",
    "with Pool(processes=12) as pool:\n",
    "    res = pool.map(func_wrapper, doc_df.loc[30000:].iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unite  indexes\n",
    "\n",
    "index = {}\n",
    "\n",
    "for i in res:\n",
    "    for key, value in i.items():\n",
    "        if key in index:\n",
    "            index[key] += value\n",
    "        else:\n",
    "            index[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index4.json', 'w') as f:\n",
    "    json.dump(index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index1.json', 'r') as f:\n",
    "    index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 5):\n",
    "    with open('index{}.json'.format(i), 'r') as f:\n",
    "        index2 = json.load(f)\n",
    "    for key, value in index2.items():\n",
    "        if key in index:\n",
    "            index[key] += value\n",
    "        else:\n",
    "            index[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index.json', 'w') as f:\n",
    "    json.dump(index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index.json', 'r') as f:\n",
    "    index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399 entries, 0 to 398\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       399 non-null    int64 \n",
      " 1   1       399 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "queries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryId = []\n",
    "\n",
    "for i in range(1, 400):\n",
    "    QueryId += [i] * 10\n",
    "    \n",
    "# size = 10 * 399"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* term-frequency\n",
    "\n",
    "$tf = \\frac{n_t}{\\sum{n_k}}$\n",
    "\n",
    "$n_t$ - число вхождений слова t в документ\n",
    "\n",
    "$\\sum{n_k}$ - общее число слов в данном документе\n",
    "\n",
    "* inverse document frequency\n",
    "\n",
    "$idf = log \\frac{|D|}{|d_i : t \\in d_i|}$ \n",
    "\n",
    "$|D|$ - число документов в коллекции\n",
    "\n",
    "$|d_i : t \\in d_i|$ - число документов из коллекции D, в которых встречается t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text[0] - QueryId\n",
    "\n",
    "text[1] - queries text\n",
    "\n",
    "docs_list = [[doc_id1, term_freq1], [doc_id2, term_freq2], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [00:14<00:00, 28.17it/s]\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"russian\") \n",
    "\n",
    "D = len(index)\n",
    "docsId = np.ones(10 * 399, dtype=int)\n",
    "\n",
    "for id, text in tqdm(queries.iterrows(), total=399, position=0):\n",
    "    words = text[1].split()\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    words_info = [] # list of lists with docs numbers and number of word entries\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        if word in index.keys():\n",
    "            words_info.append(index[word])\n",
    "        else:\n",
    "            words_info.append([])\n",
    "    # id of all docs which contain one of query's word\n",
    "    all_docs = list(set([doc_info[0] for word_info in words_info \n",
    "                         for doc_info in word_info]))\n",
    "    # word's counter for each document\n",
    "    docs_cnt = {el:0 for el in all_docs}\n",
    "    \n",
    "    # computing sum tf-idf for each document\n",
    "    for word_info in words_info:\n",
    "        if word_info:\n",
    "            idf = np.log(D / len(word_info))\n",
    "        else:\n",
    "            idf = 0\n",
    "        for doc_info in word_info: # doc_info = [doc_id, term_freq]\n",
    "            docs_cnt[doc_info[0]] += doc_info[1] * idf\n",
    "\n",
    "    # sort docs by it's frequency for query's words\n",
    "    docs_cnt = [item for item in docs_cnt.items()]\n",
    "    docs_cnt = sorted(docs_cnt, key=lambda x: x[1], reverse=True) # [(doc_id1, freq1), (doc_id2, freq2), ...]\n",
    "    i = 0\n",
    "    \n",
    "    # docsId[id - 1 + i]\n",
    "    for item in docs_cnt: # item[0] = doc_id\n",
    "        docsId[(text[0] - 1) * 10 + i] = item[0]\n",
    "        i += 1\n",
    "        if i == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'QueryId' : QueryId,\n",
    "    'DocumentId' : docsId\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>21108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryId  DocumentId\n",
       "0        1       34821\n",
       "1        1       25494\n",
       "2        1        2118\n",
       "3        1        1808\n",
       "4        1       21108"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('result.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
