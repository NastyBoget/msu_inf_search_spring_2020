{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import re\n",
    "from multiprocessing import Pool, Lock, Value\n",
    "from time import sleep\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv('queries.numerate.txt', sep='\t', header=None)\n",
    "urls = pd.read_csv('urls.numerate.txt', sep='\t', header=None)\n",
    "urls.index = urls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170717/doc.4950.dat',\n",
       " '20170717/doc.4951.dat',\n",
       " '20170717/doc.4952.dat',\n",
       " '20170717/doc.4953.dat',\n",
       " '20170717/doc.4954.dat']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docnames = []\n",
    "\n",
    "listdir = os.listdir('content/content/')\n",
    "\n",
    "for d in listdir:\n",
    "    listdocs = os.listdir('content/content/' + d)\n",
    "    listdocs.sort()\n",
    "    docnames += list(map(lambda x: d + '/' + x, listdocs))\n",
    "docnames[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2words(docname):\n",
    "    with open('content/content/' + docname, errors='ignore') as read_file:\n",
    "        lines = list(read_file)\n",
    "    url = lines[0].strip()\n",
    "    html = \"\".join(lines[1:])\n",
    "    soup = BeautifulSoup(html)\n",
    "    doc_id = urls.at[url, 0]\n",
    "    if soup.text:\n",
    "        text = re.sub(r'[^A-Za-zА-Яа-я\\.\\-]+', ' ', soup.text)\n",
    "    else:\n",
    "        text = \"\"\n",
    "    if soup.title:\n",
    "        if soup.title.text:\n",
    "            title = re.sub(r'[^A-Za-zА-Яа-я\\.\\-]+', ' ', soup.title.text)\n",
    "        else:\n",
    "            title = \"\"\n",
    "    else:\n",
    "        title = \"\"\n",
    "\n",
    "    return (title + text, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38110 objects are processed..."
     ]
    }
   ],
   "source": [
    "mutex = Lock()\n",
    "n_processed = Value('i', 0)\n",
    "\n",
    "def func_wrapper(docname):\n",
    "    res = doc2words(docname) \n",
    "    with mutex:\n",
    "        # в этом блоке можно безопасно менять общие объекты для процессов\n",
    "        global n_processed\n",
    "        n_processed.value += 1\n",
    "        if n_processed.value % 10 == 0:\n",
    "            print(f\"\\r{n_processed.value} objects are processed...\", end='', flush=True)\n",
    "    return res\n",
    "\n",
    "with Pool(processes=10) as pool:\n",
    "    docs = pool.map(func_wrapper, docnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21700</th>\n",
       "      <td>1</td>\n",
       "      <td>Хорватия Хорватия EVA.RU Вход Европа Черногори...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22010</th>\n",
       "      <td>2</td>\n",
       "      <td>Три недели в Европе. Начало Три недели в Европ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21232</th>\n",
       "      <td>3</td>\n",
       "      <td>Как правильно сделать визу в Польшу шенген Q A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20062</th>\n",
       "      <td>4</td>\n",
       "      <td>Новости Новости О нас Отрасли Страны Новости. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20345</th>\n",
       "      <td>5</td>\n",
       "      <td>Аллергия на Магические Грибы fb КулЛиб - Класс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "21700   1  Хорватия Хорватия EVA.RU Вход Европа Черногори...\n",
       "22010   2  Три недели в Европе. Начало Три недели в Европ...\n",
       "21232   3  Как правильно сделать визу в Польшу шенген Q A...\n",
       "20062   4  Новости Новости О нас Отрасли Страны Новости. ...\n",
       "20345   5  Аллергия на Магические Грибы fb КулЛиб - Класс..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_text = list(map(lambda x: x[0], docs))\n",
    "docs_id = list(map(lambda x: x[1], docs))\n",
    "\n",
    "doc_df = pd.DataFrame({'id': docs_id, 'text': docs_text})\n",
    "doc_df = doc_df.sort_values(by=['id'])\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df.to_csv(\"text_relevance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = pd.read_csv(\"text_relevance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words |= set(stopwords.words('russian'))\n",
    "with open('stop_words.txt', \"r\") as rf:\n",
    "    lines = [line.strip() for line in rf]\n",
    "stop_words |= set(lines)\n",
    "stop_words |= set(['.', '...', '-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38114 entries, 0 to 38113\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  38114 non-null  int64 \n",
      " 1   id          38114 non-null  int64 \n",
      " 2   text        38114 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 893.4+ KB\n"
     ]
    }
   ],
   "source": [
    "doc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df.index = doc_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21700</td>\n",
       "      <td>1</td>\n",
       "      <td>Хорватия Хорватия EVA.RU Вход Европа Черногори...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22010</td>\n",
       "      <td>2</td>\n",
       "      <td>Три недели в Европе. Начало Три недели в Европ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21232</td>\n",
       "      <td>3</td>\n",
       "      <td>Как правильно сделать визу в Польшу шенген Q A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20062</td>\n",
       "      <td>4</td>\n",
       "      <td>Новости Новости О нас Отрасли Страны Новости. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20345</td>\n",
       "      <td>5</td>\n",
       "      <td>Аллергия на Магические Грибы fb КулЛиб - Класс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  id                                               text\n",
       "id                                                                   \n",
       "1        21700   1  Хорватия Хорватия EVA.RU Вход Европа Черногори...\n",
       "2        22010   2  Три недели в Европе. Начало Три недели в Европ...\n",
       "3        21232   3  Как правильно сделать визу в Польшу шенген Q A...\n",
       "4        20062   4  Новости Новости О нас Отрасли Страны Новости. ...\n",
       "5        20345   5  Аллергия на Магические Грибы fb КулЛиб - Класс..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{term1: [[doc_id1, term_freq1], [doc_id2, term_freq2], ...], term2: ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 14925/20000 [2:12:13<23:49,  3.55it/s]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████▉| 19998/20000 [2:57:27<00:00,  5.33it/s]  "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "stemmer = SnowballStemmer(\"russian\") \n",
    "for id, doc in tqdm(doc_df.iterrows(), total=20000, position=0):\n",
    "    i += 1\n",
    "    if i == 20000:\n",
    "        break\n",
    "    terms = doc['text'].split()\n",
    "    terms = [t for t in terms if not t in stop_words]\n",
    "    terms = [stemmer.stem(term) for term in terms]\n",
    "    for term in terms:\n",
    "        if term in index.keys():\n",
    "            doc_id, num = index[term][-1]\n",
    "            if doc_id == id:\n",
    "                index[term][-1][1] += 1\n",
    "            else:\n",
    "                index[term].append([id, 1])\n",
    "        else:\n",
    "            index[term] = [[id, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index.json', 'w') as f:\n",
    "    json.dump(index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index.json', 'r') as f:\n",
    "    index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399 entries, 0 to 398\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       399 non-null    int64 \n",
      " 1   1       399 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "queries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryId = []\n",
    "\n",
    "for i in range(1, 400):\n",
    "    QueryId += [i] * 10\n",
    "    \n",
    "# size = 10 * 399"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO !!! lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* term-frequency\n",
    "\n",
    "$tf = \\frac{n_t}{\\sum{n_k}}$\n",
    "\n",
    "$n_t$ - число вхождений слова t в документ\n",
    "\n",
    "$\\sum{n_k}$ - общее число слов в данном документе\n",
    "\n",
    "* inverse document frequency\n",
    "\n",
    "$idf = log \\frac{|D|}{|d_i : t \\in d_i|}$ \n",
    "\n",
    "$|D|$ - число документов в коллекции\n",
    "\n",
    "$|d_i : t \\in d_i|$ - число документов из коллекции D, в которых встречается t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text[0] - QueryId\n",
    "\n",
    "text[1] - queries text\n",
    "\n",
    "docs_list = [[doc_id1, term_freq1], [doc_id2, term_freq2], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [00:09<00:00, 40.89it/s]\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"russian\") \n",
    "\n",
    "D = len(index)\n",
    "docsId = np.ones(10 * 398, dtype=int)\n",
    "\n",
    "for id, text in tqdm(queries.iterrows(), total=399, position=0):\n",
    "    words = text[1].split()\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    words_info = [] # list of lists with docs numbers and number of word entries\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        if word in index.keys():\n",
    "            words_info.append(index[word])\n",
    "        else:\n",
    "            words_info.append([])\n",
    "    # id of all docs which contain one of query's word\n",
    "    all_docs = list(set([doc_info[0] for word_info in words_info \n",
    "                         for doc_info in word_info]))\n",
    "    # word's counter for each document\n",
    "    docs_cnt = {el:0 for el in all_docs}\n",
    "    \n",
    "    # computing sum tf-idf for each document\n",
    "    for word_info in words_info:\n",
    "        if word_info:\n",
    "            idf = np.log(D / len(word_info))\n",
    "        else:\n",
    "            idf = 0\n",
    "        for doc_info in word_info: # doc_info = [doc_id, term_freq]\n",
    "            docs_cnt[doc_info[0]] += doc_info[1] * idf\n",
    "\n",
    "    # sort docs by it's frequency for query's words\n",
    "    docs_cnt = [item for item in docs_cnt.items()]\n",
    "    docs_cnt = sorted(docs_cnt, key=lambda x: x[1], reverse=True) # [(doc_id1, freq1), (doc_id2, freq2), ...]\n",
    "    i = 0\n",
    "    \n",
    "    # docsId[id - 1 + i]\n",
    "    for item in docs_cnt: # item[0] = doc_id\n",
    "        docsId[(text[0] - 1) * 10 + i] = item[0]\n",
    "        i += 1\n",
    "        if i == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'QueryId' : QueryId,\n",
    "    'DocumentId' : docsId\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryId  DocumentId\n",
       "0        1        9799\n",
       "1        1        1849\n",
       "2        1         247\n",
       "3        1        2270\n",
       "4        1       14475"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('result.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
