{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "from multiprocessing import Pool, Lock, Value\n",
    "from time import sleep\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import base64\n",
    "import numpy as np\n",
    "import zlib\n",
    "from itertools import product\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kaggle_train_data_tab_new.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(page_info):\n",
    "    html_page, url = page_info\n",
    "    html = base64.b64decode(html_page)\n",
    "    soup = BeautifulSoup(html)\n",
    "    compressibility = len(html) / len(zlib.compress(html))\n",
    "    anchor_words = 0\n",
    "    url_len = len(url)\n",
    "    url_dots = url.count(\".\")\n",
    "    url_slash = url.count(\"/\")\n",
    "    if soup.title:\n",
    "        title_words_cnt = len(soup.title.text.split())\n",
    "    else:\n",
    "        title_words_cnt = 0\n",
    "    if soup.text:\n",
    "        text = soup.text\n",
    "        words_cnt = len(text.split())\n",
    "        if text.split():\n",
    "            mean_word_length = np.mean(list(map(len, text.split())))\n",
    "        else: \n",
    "            mean_word_length = 0\n",
    "    else:\n",
    "        words_cnt = 0\n",
    "        mean_word_length = 0\n",
    "    link_cnt = len(soup.find_all('link'))\n",
    "    img_cnt = len(soup.find_all('img'))\n",
    "    style_cnt = len(soup.find_all('style'))\n",
    "    script_cnt = len(soup.find_all('script'))\n",
    "    if soup.head:\n",
    "        head_length = len(soup.head.text)\n",
    "    else:\n",
    "        head_length = 0\n",
    "    anchors = soup.find_all('a')\n",
    "    if anchors:\n",
    "        for item in anchors:\n",
    "            anchor_words += len(item.text.split())\n",
    "    else:\n",
    "        anchor_words = 0\n",
    "    anchor_cnt = len(anchors)\n",
    "    return [url_len, url_dots, url_slash,\n",
    "            title_words_cnt, words_cnt,\n",
    "            mean_word_length, link_cnt, img_cnt,\n",
    "            style_cnt, script_cnt, head_length,\n",
    "            anchor_cnt, anchor_words, compressibility]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7040 objects are processed..."
     ]
    }
   ],
   "source": [
    "mutex = Lock()\n",
    "n_processed = Value('i', 0)\n",
    "\n",
    "def func_wrapper(page):\n",
    "    res = extract_features(page) \n",
    "    with mutex:\n",
    "        # в этом блоке можно безопасно менять общие объекты для процессов\n",
    "        global n_processed\n",
    "        n_processed.value += 1\n",
    "        if n_processed.value % 10 == 0:\n",
    "            print(f\"\\r{n_processed.value} objects are processed...\", end='', flush=True)\n",
    "    return res\n",
    "\n",
    "with Pool(processes=10) as pool:\n",
    "    res = pool.map(func_wrapper, zip(df['PageBase64'].values, df['Url'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(res)\n",
    "y_train = df['Prediction'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = product(\n",
    "#     (400, 600, 800, 1000, 1200), # n_estimators\n",
    "#     (0.01, 0.1, 0.2, 0.3), # learning_rate\n",
    "#     (3, 6, 9), # max_depth\n",
    "# )\n",
    "# res_score = 0\n",
    "\n",
    "# for n_estimators, learning_rate, max_depth in list(params):\n",
    "#     clf = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "#                         max_depth=max_depth, nthread=4)\n",
    "#     res = cross_validate(clf, X_train, y_train, cv=3, scoring='f1')\n",
    "#     score = res['test_score'].mean()\n",
    "#     print(score)\n",
    "#     print(clf)\n",
    "#     if score > res_score:\n",
    "#         res_score = score\n",
    "#         res_model = clf\n",
    "        \n",
    "# res_model, res_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456146346303794"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate=0.01, max_depth=9,\n",
    "                    n_estimators=1200, nthread=4)\n",
    "scores = cross_validate(clf, X_train, y_train, cv=3, scoring='f1')\n",
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23080 objects are processed..."
     ]
    }
   ],
   "source": [
    "# clf = res_model\n",
    "clf = XGBClassifier(learning_rate=0.01, max_depth=9,\n",
    "                    n_estimators=1200, nthread=4)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "df_test = pd.read_csv('data/kaggle_test_data_tab_new.csv', sep='\\t')\n",
    "\n",
    "with Pool(processes=10) as pool:\n",
    "    res = pool.map(func_wrapper, zip(df_test['PageBase64'].values, \n",
    "                                     df_test['Url'].values))\n",
    "X_test = np.array(res)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({\n",
    "    'Id': df_test['Id'].values,\n",
    "    'Prediction': y_pred\n",
    "})\n",
    "df_pred.to_csv('my_submission.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
